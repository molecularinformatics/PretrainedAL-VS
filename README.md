

This repository provides pytorch source code, and data associated with our Journal of Chemical Information and Modeling publication, "Large-Scale Pretraining Improves Sample Efficiency of Active Learning-Based Virtual Screening".

Paper: [JCIM Link](https://pubs.acs.org/doi/10.1021/acs.jcim.3c01938) / [Arxiv Link](https://arxiv.org/abs/2309.11687)

# PretrainedAL-VS

**PretrainedAL-VS** is an Active learning framework with the pretained large Language model added as surrogate model.


<center>

<div align=center><img width="800" height="500" src="https://github.com/molecularinformatics/PretrainedAL-VS/blob/122f23c2f2b48fea3359cb61ea7f3ca2c046a9f4/assets/fig.pdf"/></div>
</center>  


## Installation

Our code is based on MolPal and MolFormer, please check the installation of MolPal and MolFormer.

* MolPal: https://github.com/coleygroup/molpal
* MolFormer:  https://github.com/IBM/molformer


